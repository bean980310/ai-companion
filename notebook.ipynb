{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename=\"outputs/ComfyUI_00309_.png\"\n",
    "\n",
    "file=os.path.basename(filename)\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "\n",
    "model_id=\"/Users/janghyeonbin/ai-companion/models/llm/gguf/Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf\"\n",
    "model=Llama(model_id)\n",
    "\n",
    "chat=\"안녕?\"\n",
    "response = model.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"당신은 유용한 AI 비서입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": chat}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AutoPipelineForText2Image.from_pretrained(\"runwayml/stable-diffusion-v1-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_download(repo_id=\"faridlazuarda/valadapt-llama-3.1-8B-it-korean\", local_dir=\"./models/llm/loras/valadapt-llama-3.1-8B-it-korean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path=\"/Volumes/EXDATA/models/LLM/transformers/llama/meta-llama__Llama-3.1-8B-Instruct\"\n",
    "lora_path=\"/Users/janghyeonbin/ai-companion/models/llm/loras/valadapt-llama-3.1-8B-it-korean\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "model.load_adapter(lora_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('./outputs/ComfyUI_00318_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image=Image.open('ComfyUI_00318_.png').convert('RGBA')\n",
    "original_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open('layer_0.png').convert('RGBA')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_alpha=image.getchannel('A')\n",
    "new_alpha.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_alpha=ImageOps.invert(new_alpha)\n",
    "new_alpha.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask=Image.new(\"RGBA\", image.size)\n",
    "new_mask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask.putalpha(new_alpha)\n",
    "new_mask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=os.getenv('HF_TOKEN')\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api=HfApi(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=api.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=api.list_models(task='audio-text-to-text', library=\"transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack\n",
    "import scipy.io.wavfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2mp3():\n",
    "    tts=gTTS('Hello',lang='en')\n",
    "    tts.save('text1.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2mp3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2wav():\n",
    "    tts=gTTS('Hello', lang=\"en\")\n",
    "    tts.save('hello.mp3')\n",
    "    \n",
    "    w=AudioSegment.from_mp3('hello.mp3')\n",
    "    w.export('Hello.wav', format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2wav(text, lang):\n",
    "    tts=gTTS(text, lang=lang)\n",
    "    tts.save(f\"{text}.mp3\")\n",
    "    \n",
    "    w=AudioSegment.from_mp3(f\"{text}.mp3\")\n",
    "    w.export(f\"{text}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2wav('Hello', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2wav('안녕하세요', lang='ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(path='characters_info', glob=\"*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "docs.sort(key=lambda x: x.metadata.get('source', ''))\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_classic.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_document_by_sections(text):\n",
    "    \"\"\"\n",
    "    텍스트에서 [항목] 형태의 섹션을 찾아서 (섹션 제목, 내용) 튜플 리스트로 반환하는 함수.\n",
    "    \"\"\"\n",
    "    # 정규표현식 패턴: 대괄호 안에 항목명, 그 다음 내용은 다음 대괄호가 나오기 전까지\n",
    "    pattern = re.compile(r'\\[(.*?)\\]\\s*(.*?)(?=\\n\\s*\\[|$)', re.DOTALL)\n",
    "    sections = []\n",
    "    for match in pattern.finditer(text):\n",
    "        section_title = match.group(1).strip()\n",
    "        section_content = match.group(2).strip()\n",
    "        sections.append((section_title, section_content))\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언어 이름과 코드 매핑 딕셔너리\n",
    "LANGUAGE_MAP = {\n",
    "    \"한국어\": \"ko\",\n",
    "    \"日本語\": \"ja\",\n",
    "    \"简体中文\": \"zh_CN\",\n",
    "    \"繁體中文\": \"zh_TW\",\n",
    "    \"English\": \"en\"\n",
    "}\n",
    "\n",
    "def extract_language_code(heading):\n",
    "    \"\"\"\n",
    "    헤딩 텍스트 (예: \"## 한국어\")에서 언어 이름을 추출하여\n",
    "    매핑 딕셔너리를 통해 언어 코드를 반환하는 함수.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"##\\s*(.+)\", heading)\n",
    "    if match:\n",
    "        lang_name = match.group(1).strip()\n",
    "        return LANGUAGE_MAP.get(lang_name, lang_name)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multilang_document(doc):\n",
    "    \"\"\"\n",
    "    파일 하나에 여러 언어 섹션이 있을 때,\n",
    "    각 언어 헤딩(예: \"## 한국어\")을 기준으로 블록을 분리하고,\n",
    "    각 블록 내에서 [설정], [성격] 등 섹션별로 분리한 Document 리스트를 반환.\n",
    "    \"\"\"\n",
    "    text = doc.page_content\n",
    "    # 언어 헤딩(## 로 시작하는 줄)을 기준으로 분리 (헤딩을 포함하도록 분리)\n",
    "    blocks = re.split(r'(?=##\\s*)', text)\n",
    "    \n",
    "    processed = []\n",
    "    for block in blocks:\n",
    "        if block.startswith(\"##\"):\n",
    "            # 첫 줄에서 언어 헤딩을 추출\n",
    "            lines = block.splitlines()\n",
    "            lang_code = extract_language_code(lines[0])\n",
    "            # 헤딩 부분을 제거한 나머지 내용 사용\n",
    "            content = \"\\n\".join(lines[1:]).strip()\n",
    "            # 이전에 정의한 섹션 분리 함수 사용\n",
    "            sections = split_document_by_sections(content)\n",
    "            for section_title, section_content in sections:\n",
    "                new_doc = Document(\n",
    "                    page_content=section_content,\n",
    "                    metadata={\n",
    "                        \"language\": lang_code,\n",
    "                        \"section\": section_title,\n",
    "                        \"source\": doc.metadata.get(\"source\", \"unknown\")\n",
    "                    }\n",
    "                )\n",
    "                processed.append(new_doc)\n",
    "        else:\n",
    "            # 만약 블록이 언어 헤딩 없이 나온다면, 무시하거나 기본값 설정 가능\n",
    "            pass\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc)\n",
    "    processed_docs = process_multilang_document(doc)\n",
    "    all_processed_docs.extend(processed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in all_processed_docs:\n",
    "    print(doc.metadata, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"BAAI/bge-m3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(\n",
    "    documents=all_processed_docs, embedding=embedding_model, distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_count = vectorstore.index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"미나미 아스카의 성격과 외모에 대해 어떻게 생각해?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = embedding_model.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_docs = retriever.invoke(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in basic_docs:\n",
    "    print(doc.metadata, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3.1-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('meta-llama/Meta-Llama-3.1-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.repetition_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.themes.builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 変換するディレクトリを指定します\n",
    "input_dir = \"/tmp/ComfyUI/models/checkpoints/\"\n",
    "\n",
    "# 指定したディレクトリ内のすべてのsafetensorsファイルを取得\n",
    "safetensors_files = list(Path(input_dir).glob(\"*.safetensors\"))\n",
    "\n",
    "def convert_model(file_path: str):\n",
    "    print(f\"変換中: {file_path}\")\n",
    "    \n",
    "    # メタデータの読み込み\n",
    "    try:\n",
    "        with safe_open(file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            metadata = f.metadata()\n",
    "            metadata = metadata if metadata is not None else {}\n",
    "    except Exception as e:\n",
    "        print(f\"メタデータの読み取り中にエラーが発生しました: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # モデルの変換\n",
    "    try:\n",
    "        sd_pruned = {}\n",
    "        with safe_open(file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for key in tqdm(f.keys(), desc=\"テンソルを変換中\"):\n",
    "                tensor = f.get_tensor(key)\n",
    "                sd_pruned[key] = tensor.to(torch.float8_e4m3fn)\n",
    "\n",
    "        # 変換したモデルを保存（元のディレクトリに）\n",
    "        output_dir = os.path.dirname(file_path)\n",
    "        model_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_filename = f\"{model_name}_fp8.safetensors\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        save_file(sd_pruned, output_path, metadata={\"format\": \"pt\", **metadata})\n",
    "        print(f\"ファイルが正常に保存されました: {output_path}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"変換中にエラーが発生しました: {str(e)}\")\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"models/diffusion/checkpoints/sdxl/animagine-xl-4.0-opt.safetensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model_to_int8(file_path: str):\n",
    "    print(f\"Converting: {file_path}\")\n",
    "    \n",
    "    # Read metadata\n",
    "    try:\n",
    "        with safe_open(file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            metadata = f.metadata()\n",
    "            metadata = metadata if metadata is not None else {}\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # Convert the model\n",
    "    try:\n",
    "        sd_pruned = {}\n",
    "        with safe_open(file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for key in tqdm(f.keys(), desc=\"Converting tensors\"):\n",
    "                tensor = f.get_tensor(key)\n",
    "                sd_pruned[key] = tensor.to(torch.float8_e4m3fn)\n",
    "\n",
    "        # Save the converted model (in the original directory)\n",
    "        output_dir = os.path.dirname(file_path)\n",
    "        model_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_filename = f\"{model_name}_fp8.safetensors\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        save_file(sd_pruned, output_path, metadata={\"format\": \"pt\", **metadata})\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = HfApi(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.create_repo(repo_id=\"mlx-community/aya-expanse-8b-8bit\",token=token)\n",
    "api.upload_folder(\n",
    "    folder_path=\"models/llm/mlx/CohereForAI__aya-expanse-8b-8bit\",\n",
    "    repo_id=\"mlx-community/aya-expanse-8b-8bit\",\n",
    "    token=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.upload_folder(\n",
    "    folder_path=\"models/diffusion/loras/sd35_medium/Tomboy_for_SD3.5_Medium_test\",\n",
    "    repo_id=\"bean980310/Tomboy_for_SD3.5_Medium_test\",\n",
    "    ignore_patterns=[\"._*\"],\n",
    "    token=token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\n",
    "\n",
    "system_message = SystemMessage(content=\"당신은 유용한 AI 비서입니다.\")\n",
    "user_message = HumanMessage(content=\"안녕?\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_message.content),\n",
    "    (\"user\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = prompt.format_messages(input=user_message.content)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.files.create(\n",
    "    file=Path(\"/Users/janghyeonbin/Pictures/ComfyUI_00085_.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import sys\n",
    "import time\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "video = openai.videos.create(\n",
    "    model=\"sora-2-pro\",\n",
    "    input_reference=Path(\"/Users/janghyeonbin/Pictures/ComfyUI_00085_resized.png\"),\n",
    "    seconds=\"8\",\n",
    "    size=\"1280x720\",\n",
    "    prompt=\"Minami Asuka the tomboyish girl is dual wielding swords. her short hair and clothes flutter in the wind. she says 「みんな、俺についてきて！」\",\n",
    ")\n",
    "\n",
    "print(video.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = openai.videos.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = page.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.videos.download_content(\n",
    "    video_id=video.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.data[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    if any(k in m.id.lower() for k in [\"gpt-4o\", \"gpt-4.1\", \"gpt-5\", \"gpt-oss\"]):\n",
    "        print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    if any(k in m.id.lower() for k in [\"gpt-4o\", \"gpt-4.1\", \"gpt-5\", \"gpt-oss\"]) and all(k not in m.id.lower() for k in [\"image\", \"realtime\", \"tts\", \"audio\", \"transcribe\", \"codex\", \"search\", \"preview\"]) and all(k not in m.id.lower() for k in [\"gpt-4.1-mini\", \"gpt-4.1-nano\", 'gpt-4o-mini']):\n",
    "        print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    if any(k in m.id.lower() for k in [\"dall-e-3\", \"image\"]):\n",
    "        print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    if \"tts\" in m.id.lower():\n",
    "        print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    if any(k in m.id.lower() for k in [\"whisper\", \"transcribe\"]):\n",
    "        print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    if \"text-embedding-3\" in m.id.lower():\n",
    "        print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    if any(k in m.id.lower() for k in [\"audio\", \"realtime\"]):\n",
    "        print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.data:\n",
    "    if \"sora\" in m.id.lower():\n",
    "        print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.models.list().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in client.models.list().data:\n",
    "    print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.models.list().page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.models.list().page[0].display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for m in response.page:\n",
    "    models.append(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = []\n",
    "for m in response.page:\n",
    "    if \"generateContent\" in m.supported_actions:\n",
    "        llm.append(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = []\n",
    "for m in response.page:\n",
    "    if \"generateContent\" in m.supported_actions and any(k in m.name for k in [\"gemini\", \"gemma\"]) and all(k not in m.name for k in [\"embedding\", \"tts\", \"exp\", \"preview\", \"gemini-2.0\"]):\n",
    "        llm.append(m.name)\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = []\n",
    "for m in response.page:\n",
    "    if \"imagen\" in m.name:\n",
    "        image_model.append(m.name)\n",
    "\n",
    "image_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xai_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = xai_sdk.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list_language_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmstudio as lms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = lms.list_downloaded_models(\"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in llm:\n",
    "    print(m.model_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models.models:\n",
    "    print(m.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_address=\"127.0.0.1:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_route = f\"http://{server_address}/models/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = requests.get(model_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\"ilxl/Illustrious-XL-v1.0.safetensors\", \"sd15/AOM3A1B_orangemixs.safetensors\", \"sd15/Anything-ink.safetensors\", \"sd15/AnythingXL_v50.safetensors\", \"sd15/Counterfeit-V3.0_fix_fp16.safetensors\", \"sd15/anythingV3_fp16.safetensors\", \"sd15/sd-v1-5-inpainting.ckpt\", \"sd15/v1-5-pruned-emaonly.safetensors\", \"sd35_large/emi3.safetensors\", \"sdxl/AnythingXL_xl.safetensors\", \"sdxl/AnythingXL_xlHyper8stepsCFG1.safetensors\", \"sdxl/animagine-xl-3.1.safetensors\", \"sdxl/animagine-xl-4.0-opt.safetensors\", \"sdxl/fp8/animagine-xl-4.0-opt-fp8.safetensors\", \"sdxl/sd_xl_base_1.0.safetensors\", \"sdxl/sd_xl_refiner_1.0.safetensors\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.content[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_byte = models.content[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = models.content[1:-1].decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"ilxl/Illustrious-XL-v1.0.safetensors\", \"sd15/AOM3A1B_orangemixs.safetensors\", \"sd15/Anything-ink.safetensors\", \"sd15/AnythingXL_v50.safetensors\", \"sd15/Counterfeit-V3.0_fix_fp16.safetensors\", \"sd15/anythingV3_fp16.safetensors\", \"sd15/sd-v1-5-inpainting.ckpt\", \"sd15/v1-5-pruned-emaonly.safetensors\", \"sd35_large/emi3.safetensors\", \"sdxl/AnythingXL_xl.safetensors\", \"sdxl/AnythingXL_xlHyper8stepsCFG1.safetensors\", \"sdxl/animagine-xl-3.1.safetensors\", \"sdxl/animagine-xl-4.0-opt.safetensors\", \"sdxl/fp8/animagine-xl-4.0-opt-fp8.safetensors\", \"sdxl/sd_xl_base_1.0.safetensors\", \"sdxl/sd_xl_refiner_1.0.safetensors\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_list = [x.decode('utf-8') for x in checkpoints_byte.split(b', ') if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoints)\n",
    "print(type(checkpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_list = [x for x in checkpoints.replace(\"\\\"\", \"\").strip().split(', ') if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ilxl/Illustrious-XL-v1.0.safetensors',\n",
       " 'sd15/AOM3A1B_orangemixs.safetensors',\n",
       " 'sd15/Anything-ink.safetensors',\n",
       " 'sd15/AnythingXL_v50.safetensors',\n",
       " 'sd15/Counterfeit-V3.0_fix_fp16.safetensors',\n",
       " 'sd15/anythingV3_fp16.safetensors',\n",
       " 'sd15/sd-v1-5-inpainting.ckpt',\n",
       " 'sd15/v1-5-pruned-emaonly.safetensors',\n",
       " 'sd35_large/emi3.safetensors',\n",
       " 'sdxl/AnythingXL_xl.safetensors',\n",
       " 'sdxl/AnythingXL_xlHyper8stepsCFG1.safetensors',\n",
       " 'sdxl/animagine-xl-3.1.safetensors',\n",
       " 'sdxl/animagine-xl-4.0-opt.safetensors',\n",
       " 'sdxl/fp8/animagine-xl-4.0-opt-fp8.safetensors',\n",
       " 'sdxl/sd_xl_base_1.0.safetensors',\n",
       " 'sdxl/sd_xl_refiner_1.0.safetensors']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in checkpoint_list:\n",
    "    print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
