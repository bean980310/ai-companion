{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filename=\"outputs/ComfyUI_00309_.png\"\n",
    "\n",
    "file=os.path.basename(filename)\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import json\n",
    "\n",
    "model_id=\"/Users/janghyeonbin/ai-companion/models/llm/gguf/Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf\"\n",
    "model=Llama(model_id)\n",
    "\n",
    "chat=\"안녕?\"\n",
    "response = model.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"당신은 유용한 AI 비서입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": chat}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AutoPipelineForText2Image.from_pretrained(\"runwayml/stable-diffusion-v1-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_download(repo_id=\"faridlazuarda/valadapt-llama-3.1-8B-it-korean\", local_dir=\"./models/llm/loras/valadapt-llama-3.1-8B-it-korean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path=\"/Volumes/EXDATA/models/LLM/transformers/llama/meta-llama__Llama-3.1-8B-Instruct\"\n",
    "lora_path=\"/Users/janghyeonbin/ai-companion/models/llm/loras/valadapt-llama-3.1-8B-it-korean\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "model.load_adapter(lora_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('./outputs/ComfyUI_00318_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image=Image.open('ComfyUI_00318_.png').convert('RGBA')\n",
    "original_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=Image.open('layer_0.png').convert('RGBA')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_alpha=image.getchannel('A')\n",
    "new_alpha.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_alpha=ImageOps.invert(new_alpha)\n",
    "new_alpha.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask=Image.new(\"RGBA\", image.size)\n",
    "new_mask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask.putalpha(new_alpha)\n",
    "new_mask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token=os.getenv('HF_TOKEN')\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api=HfApi(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=api.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=api.list_models(task='audio-text-to-text', library=\"transformers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack\n",
    "import scipy.io.wavfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2mp3():\n",
    "    tts=gTTS('Hello',lang='en')\n",
    "    tts.save('text1.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2mp3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2wav():\n",
    "    tts=gTTS('Hello', lang=\"en\")\n",
    "    tts.save('hello.mp3')\n",
    "    \n",
    "    w=AudioSegment.from_mp3('hello.mp3')\n",
    "    w.export('Hello.wav', format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2wav()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2wav(text, lang):\n",
    "    tts=gTTS(text, lang=lang)\n",
    "    tts.save(f\"{text}.mp3\")\n",
    "    \n",
    "    w=AudioSegment.from_mp3(f\"{text}.mp3\")\n",
    "    w.export(f\"{text}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2wav('Hello', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2wav('안녕하세요', lang='ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(path='characters_info', glob=\"*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "docs.sort(key=lambda x: x.metadata.get('source', ''))\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_document_by_sections(text):\n",
    "    \"\"\"\n",
    "    텍스트에서 [항목] 형태의 섹션을 찾아서 (섹션 제목, 내용) 튜플 리스트로 반환하는 함수.\n",
    "    \"\"\"\n",
    "    # 정규표현식 패턴: 대괄호 안에 항목명, 그 다음 내용은 다음 대괄호가 나오기 전까지\n",
    "    pattern = re.compile(r'\\[(.*?)\\]\\s*(.*?)(?=\\n\\s*\\[|$)', re.DOTALL)\n",
    "    sections = []\n",
    "    for match in pattern.finditer(text):\n",
    "        section_title = match.group(1).strip()\n",
    "        section_content = match.group(2).strip()\n",
    "        sections.append((section_title, section_content))\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언어 이름과 코드 매핑 딕셔너리\n",
    "LANGUAGE_MAP = {\n",
    "    \"한국어\": \"ko\",\n",
    "    \"日本語\": \"ja\",\n",
    "    \"简体中文\": \"zh_CN\",\n",
    "    \"繁體中文\": \"zh_TW\",\n",
    "    \"English\": \"en\"\n",
    "}\n",
    "\n",
    "def extract_language_code(heading):\n",
    "    \"\"\"\n",
    "    헤딩 텍스트 (예: \"## 한국어\")에서 언어 이름을 추출하여\n",
    "    매핑 딕셔너리를 통해 언어 코드를 반환하는 함수.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"##\\s*(.+)\", heading)\n",
    "    if match:\n",
    "        lang_name = match.group(1).strip()\n",
    "        return LANGUAGE_MAP.get(lang_name, lang_name)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_multilang_document(doc):\n",
    "    \"\"\"\n",
    "    파일 하나에 여러 언어 섹션이 있을 때,\n",
    "    각 언어 헤딩(예: \"## 한국어\")을 기준으로 블록을 분리하고,\n",
    "    각 블록 내에서 [설정], [성격] 등 섹션별로 분리한 Document 리스트를 반환.\n",
    "    \"\"\"\n",
    "    text = doc.page_content\n",
    "    # 언어 헤딩(## 로 시작하는 줄)을 기준으로 분리 (헤딩을 포함하도록 분리)\n",
    "    blocks = re.split(r'(?=##\\s*)', text)\n",
    "    \n",
    "    processed = []\n",
    "    for block in blocks:\n",
    "        if block.startswith(\"##\"):\n",
    "            # 첫 줄에서 언어 헤딩을 추출\n",
    "            lines = block.splitlines()\n",
    "            lang_code = extract_language_code(lines[0])\n",
    "            # 헤딩 부분을 제거한 나머지 내용 사용\n",
    "            content = \"\\n\".join(lines[1:]).strip()\n",
    "            # 이전에 정의한 섹션 분리 함수 사용\n",
    "            sections = split_document_by_sections(content)\n",
    "            for section_title, section_content in sections:\n",
    "                new_doc = Document(\n",
    "                    page_content=section_content,\n",
    "                    metadata={\n",
    "                        \"language\": lang_code,\n",
    "                        \"section\": section_title,\n",
    "                        \"source\": doc.metadata.get(\"source\", \"unknown\")\n",
    "                    }\n",
    "                )\n",
    "                processed.append(new_doc)\n",
    "        else:\n",
    "            # 만약 블록이 언어 헤딩 없이 나온다면, 무시하거나 기본값 설정 가능\n",
    "            pass\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc)\n",
    "    processed_docs = process_multilang_document(doc)\n",
    "    all_processed_docs.extend(processed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in all_processed_docs:\n",
    "    print(doc.metadata, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"BAAI/bge-m3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(\n",
    "    documents=all_processed_docs, embedding=embedding_model, distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_count = vectorstore.index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"미나미 아스카의 성격과 외모에 대해 어떻게 생각해?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = embedding_model.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_docs = retriever.invoke(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in basic_docs:\n",
    "    print(doc.metadata, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Meta-Llama-3.1-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained('meta-llama/Meta-Llama-3.1-8B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.top_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.repetition_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.themes.builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 変換するディレクトリを指定します\n",
    "input_dir = \"/tmp/ComfyUI/models/checkpoints/\"\n",
    "\n",
    "# 指定したディレクトリ内のすべてのsafetensorsファイルを取得\n",
    "safetensors_files = list(Path(input_dir).glob(\"*.safetensors\"))\n",
    "\n",
    "def convert_model(file_path: str):\n",
    "    print(f\"変換中: {file_path}\")\n",
    "    \n",
    "    # メタデータの読み込み\n",
    "    try:\n",
    "        with safe_open(file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            metadata = f.metadata()\n",
    "            metadata = metadata if metadata is not None else {}\n",
    "    except Exception as e:\n",
    "        print(f\"メタデータの読み取り中にエラーが発生しました: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # モデルの変換\n",
    "    try:\n",
    "        sd_pruned = {}\n",
    "        with safe_open(file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for key in tqdm(f.keys(), desc=\"テンソルを変換中\"):\n",
    "                tensor = f.get_tensor(key)\n",
    "                sd_pruned[key] = tensor.to(torch.float8_e4m3fn)\n",
    "\n",
    "        # 変換したモデルを保存（元のディレクトリに）\n",
    "        output_dir = os.path.dirname(file_path)\n",
    "        model_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_filename = f\"{model_name}_fp8.safetensors\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        save_file(sd_pruned, output_path, metadata={\"format\": \"pt\", **metadata})\n",
    "        print(f\"ファイルが正常に保存されました: {output_path}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"変換中にエラーが発生しました: {str(e)}\")\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"models/diffusion/checkpoints/sdxl/animagine-xl-4.0-opt.safetensors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_model(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_model_to_int8(file_path: str):\n",
    "    print(f\"Converting: {file_path}\")\n",
    "    \n",
    "    # Read metadata\n",
    "    try:\n",
    "        with safe_open(file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            metadata = f.metadata()\n",
    "            metadata = metadata if metadata is not None else {}\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # Convert the model\n",
    "    try:\n",
    "        sd_pruned = {}\n",
    "        with safe_open(file_path, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for key in tqdm(f.keys(), desc=\"Converting tensors\"):\n",
    "                tensor = f.get_tensor(key)\n",
    "                sd_pruned[key] = tensor.to(torch.float8_e4m3fn)\n",
    "\n",
    "        # Save the converted model (in the original directory)\n",
    "        output_dir = os.path.dirname(file_path)\n",
    "        model_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_filename = f\"{model_name}_fp8.safetensors\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        save_file(sd_pruned, output_path, metadata={\"format\": \"pt\", **metadata})\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {str(e)}\")\n",
    "        return False\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
