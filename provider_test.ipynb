{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6455ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, get_key, set_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32da5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=get_key('.env', 'OPENAI_API_KEY'))\n",
    "\n",
    "models = client.models.list()\n",
    "\n",
    "models\n",
    "\n",
    "model_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    if \"image\" in m.id.lower():\n",
    "        model_list.append(m.id)\n",
    "\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba75793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='gpt-5.1-codex-mini', created=1763007109, object='model', owned_by='system'), Model(id='gpt-5.1-chat-latest', created=1762547951, object='model', owned_by='system'), Model(id='gpt-5.1-2025-11-13', created=1762800353, object='model', owned_by='system'), Model(id='gpt-5.1', created=1762800673, object='model', owned_by='system'), Model(id='gpt-5.1-codex', created=1762988221, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system'), Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'), Model(id='o1', created=1734375816, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='o3-mini', created=1737146383, object='model', owned_by='system'), Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'), Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'), Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'), Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system'), Model(id='o1-pro', created=1742251791, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'), Model(id='o3-2025-04-16', created=1744133301, object='model', owned_by='system'), Model(id='o4-mini-2025-04-16', created=1744133506, object='model', owned_by='system'), Model(id='o3', created=1744225308, object='model', owned_by='system'), Model(id='o4-mini', created=1744225351, object='model', owned_by='system'), Model(id='gpt-4.1-2025-04-14', created=1744315746, object='model', owned_by='system'), Model(id='gpt-4.1', created=1744316542, object='model', owned_by='system'), Model(id='gpt-4.1-mini-2025-04-14', created=1744317547, object='model', owned_by='system'), Model(id='gpt-4.1-mini', created=1744318173, object='model', owned_by='system'), Model(id='gpt-4.1-nano-2025-04-14', created=1744321025, object='model', owned_by='system'), Model(id='gpt-4.1-nano', created=1744321707, object='model', owned_by='system'), Model(id='gpt-image-1', created=1745517030, object='model', owned_by='system'), Model(id='codex-mini-latest', created=1746673257, object='model', owned_by='system'), Model(id='o3-pro', created=1748475349, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2025-06-03', created=1748907838, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2025-06-03', created=1748908498, object='model', owned_by='system'), Model(id='o3-pro-2025-06-10', created=1749166761, object='model', owned_by='system'), Model(id='o4-mini-deep-research', created=1749685485, object='model', owned_by='system'), Model(id='o3-deep-research', created=1749840121, object='model', owned_by='system'), Model(id='gpt-4o-transcribe-diarize', created=1750798887, object='model', owned_by='system'), Model(id='o3-deep-research-2025-06-26', created=1750865219, object='model', owned_by='system'), Model(id='o4-mini-deep-research-2025-06-26', created=1750866121, object='model', owned_by='system'), Model(id='gpt-5-chat-latest', created=1754073306, object='model', owned_by='system'), Model(id='gpt-5-2025-08-07', created=1754075360, object='model', owned_by='system'), Model(id='gpt-5', created=1754425777, object='model', owned_by='system'), Model(id='gpt-5-mini-2025-08-07', created=1754425867, object='model', owned_by='system'), Model(id='gpt-5-mini', created=1754425928, object='model', owned_by='system'), Model(id='gpt-5-nano-2025-08-07', created=1754426303, object='model', owned_by='system'), Model(id='gpt-5-nano', created=1754426384, object='model', owned_by='system'), Model(id='gpt-audio-2025-08-28', created=1756256146, object='model', owned_by='system'), Model(id='gpt-realtime', created=1756271701, object='model', owned_by='system'), Model(id='gpt-realtime-2025-08-28', created=1756271773, object='model', owned_by='system'), Model(id='gpt-audio', created=1756339249, object='model', owned_by='system'), Model(id='gpt-5-codex', created=1757527818, object='model', owned_by='system'), Model(id='gpt-image-1-mini', created=1758845821, object='model', owned_by='system'), Model(id='gpt-5-pro-2025-10-06', created=1759469707, object='model', owned_by='system'), Model(id='gpt-5-pro', created=1759469822, object='model', owned_by='system'), Model(id='gpt-audio-mini', created=1759512027, object='model', owned_by='system'), Model(id='gpt-audio-mini-2025-10-06', created=1759512137, object='model', owned_by='system'), Model(id='gpt-5-search-api', created=1759514629, object='model', owned_by='system'), Model(id='gpt-realtime-mini', created=1759517133, object='model', owned_by='system'), Model(id='gpt-realtime-mini-2025-10-06', created=1759517175, object='model', owned_by='system'), Model(id='sora-2', created=1759708615, object='model', owned_by='system'), Model(id='sora-2-pro', created=1759708663, object='model', owned_by='system'), Model(id='gpt-5-search-api-2025-10-14', created=1760043960, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')], object='list')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in models:\n",
    "    if \"image\" in m.id.lower():\n",
    "        model_list.append(m.id)\n",
    "\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc6102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225118e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3804948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-image-1', 'gpt-image-1-mini']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4ef44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic(api_key=get_key(\".env\", \"ANTHROPIC_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dab79a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SyncAPIClient.get_api_list() missing 1 required positional argument: 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_api_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: SyncAPIClient.get_api_list() missing 1 required positional argument: 'path'"
     ]
    }
   ],
   "source": [
    "client.get_api_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb81458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=get_key(\".env\", \"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bbff25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55d24c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21012da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4ce9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models.page:\n",
    "    temp.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d6de9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models.page:\n",
    "    model_list.append(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0649d0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(\n",
       "   description='Veo 3.1 fast',\n",
       "   display_name='Veo 3.1 fast',\n",
       "   input_token_limit=480,\n",
       "   name='models/veo-3.1-fast-generate-preview',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predictLongRunning',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='3.1'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.0 Flash 001',\n",
       "   display_name='Gemini 2.0 Flash 001',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-live-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'bidiGenerateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini Live 2.5 Flash Preview',\n",
       "   display_name='Gemini Live 2.5 Flash Preview',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-live-2.5-flash-preview',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'bidiGenerateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Flash Live Preview',\n",
       "   display_name='Gemini 2.5 Flash Live Preview',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-live-preview',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'bidiGenerateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Latest release of Gemini 2.5 Flash Native Audio',\n",
       "   display_name='Gemini 2.5 Flash Native Audio Latest',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-native-audio-latest',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'countTokens',\n",
       "     'bidiGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='Gemini 2.5 Flash Native Audio Latest'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
       "   display_name='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-native-audio-preview-09-2025',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'countTokens',\n",
       "     'bidiGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19'\n",
       " ),\n",
       " Model(\n",
       "   description='Obtain a distributed representation of a text.',\n",
       "   display_name='Embedding Gecko',\n",
       "   input_token_limit=1024,\n",
       "   name='models/embedding-gecko-001',\n",
       "   output_token_limit=1,\n",
       "   supported_actions=[\n",
       "     'embedText',\n",
       "     'countTextTokens',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.',\n",
       "   display_name='Gemini 2.5 Flash',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
       "   display_name='Gemini 2.5 Pro',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-pro',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.5'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.0 Flash Experimental',\n",
       "   display_name='Gemini 2.0 Flash Experimental',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-exp',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'bidiGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=40,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.0 Flash',\n",
       "   display_name='Gemini 2.0 Flash',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=40,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.',\n",
       "   display_name='Gemini 2.0 Flash 001',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=40,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
       "   display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-exp-image-generation',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'bidiGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=40,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Stable version of Gemini 2.0 Flash-Lite',\n",
       "   display_name='Gemini 2.0 Flash-Lite 001',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-lite-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=40,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.0 Flash-Lite',\n",
       "   display_name='Gemini 2.0 Flash-Lite',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-lite',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=40,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
       "   display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-lite-preview-02-05',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=40,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='preview-02-05'\n",
       " ),\n",
       " Model(\n",
       "   description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
       "   display_name='Gemini 2.0 Flash-Lite Preview',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-lite-preview',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=40,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='preview-02-05'\n",
       " ),\n",
       " Model(\n",
       "   description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
       "   display_name='Gemini 2.0 Pro Experimental',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-pro-exp',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.5-exp-03-25'\n",
       " ),\n",
       " Model(\n",
       "   description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
       "   display_name='Gemini 2.0 Pro Experimental 02-05',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-pro-exp-02-05',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.5-exp-03-25'\n",
       " ),\n",
       " Model(\n",
       "   description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
       "   display_name='Gemini Experimental 1206',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-exp-1206',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.5-exp-03-25'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Flash Preview TTS',\n",
       "   display_name='Gemini 2.5 Flash Preview TTS',\n",
       "   input_token_limit=8192,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-preview-tts',\n",
       "   output_token_limit=16384,\n",
       "   supported_actions=[\n",
       "     'countTokens',\n",
       "     'generateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='gemini-2.5-flash-exp-tts-2025-05-19'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Pro Preview TTS',\n",
       "   display_name='Gemini 2.5 Pro Preview TTS',\n",
       "   input_token_limit=8192,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-pro-preview-tts',\n",
       "   output_token_limit=16384,\n",
       "   supported_actions=[\n",
       "     'countTokens',\n",
       "     'generateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='gemini-2.5-pro-preview-tts-2025-05-19'\n",
       " ),\n",
       " Model(\n",
       "   display_name='Gemma 3 1B',\n",
       "   input_token_limit=32768,\n",
       "   name='models/gemma-3-1b-it',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   display_name='Gemma 3 4B',\n",
       "   input_token_limit=32768,\n",
       "   name='models/gemma-3-4b-it',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   display_name='Gemma 3 12B',\n",
       "   input_token_limit=32768,\n",
       "   name='models/gemma-3-12b-it',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   display_name='Gemma 3 27B',\n",
       "   input_token_limit=131072,\n",
       "   name='models/gemma-3-27b-it',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   display_name='Gemma 3n E4B',\n",
       "   input_token_limit=8192,\n",
       "   name='models/gemma-3n-e4b-it',\n",
       "   output_token_limit=2048,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   display_name='Gemma 3n E2B',\n",
       "   input_token_limit=8192,\n",
       "   name='models/gemma-3n-e2b-it',\n",
       "   output_token_limit=2048,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Latest release of Gemini Flash',\n",
       "   display_name='Gemini Flash Latest',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-flash-latest',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='Gemini Flash Latest'\n",
       " ),\n",
       " Model(\n",
       "   description='Latest release of Gemini Flash-Lite',\n",
       "   display_name='Gemini Flash-Lite Latest',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-flash-lite-latest',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='Gemini Flash-Lite Latest'\n",
       " ),\n",
       " Model(\n",
       "   description='Latest release of Gemini Pro',\n",
       "   display_name='Gemini Pro Latest',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-pro-latest',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='Gemini Pro Latest'\n",
       " ),\n",
       " Model(\n",
       "   description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
       "   display_name='Gemini 2.5 Flash-Lite',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-lite',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Flash Preview Image',\n",
       "   display_name='Nano Banana',\n",
       "   input_token_limit=32768,\n",
       "   max_temperature=1.0,\n",
       "   name='models/gemini-2.5-flash-image-preview',\n",
       "   output_token_limit=32768,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Flash Preview Image',\n",
       "   display_name='Nano Banana',\n",
       "   input_token_limit=32768,\n",
       "   max_temperature=1.0,\n",
       "   name='models/gemini-2.5-flash-image',\n",
       "   output_token_limit=32768,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Flash Preview Sep 2025',\n",
       "   display_name='Gemini 2.5 Flash Preview Sep 2025',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-preview-09-2025',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='Gemini 2.5 Flash Preview 09-2025'\n",
       " ),\n",
       " Model(\n",
       "   description='Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite',\n",
       "   display_name='Gemini 2.5 Flash-Lite Preview Sep 2025',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-lite-preview-09-2025',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.5-preview-09-25'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 3 Pro Preview',\n",
       "   display_name='Gemini 3 Pro Preview',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-3-pro-preview',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'createCachedContent',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='3-pro-preview-11-2025'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 3 Pro Image Preview',\n",
       "   display_name='Nano Banana Pro',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=1.0,\n",
       "   name='models/gemini-3-pro-image-preview',\n",
       "   output_token_limit=32768,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='3.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 3 Pro Image Preview',\n",
       "   display_name='Nano Banana Pro',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=1.0,\n",
       "   name='models/nano-banana-pro-preview',\n",
       "   output_token_limit=32768,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "     'batchGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='3.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini Robotics-ER 1.5 Preview',\n",
       "   display_name='Gemini Robotics-ER 1.5 Preview',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-robotics-er-1.5-preview',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='1.5-preview'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Computer Use Preview 10-2025',\n",
       "   display_name='Gemini 2.5 Computer Use Preview 10-2025',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-computer-use-preview-10-2025',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'generateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='Gemini 2.5 Computer Use Preview 10-2025'\n",
       " ),\n",
       " Model(\n",
       "   description='Obtain a distributed representation of a text.',\n",
       "   display_name='Embedding 001',\n",
       "   input_token_limit=2048,\n",
       "   name='models/embedding-001',\n",
       "   output_token_limit=1,\n",
       "   supported_actions=[\n",
       "     'embedContent',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Obtain a distributed representation of a text.',\n",
       "   display_name='Text Embedding 004',\n",
       "   input_token_limit=2048,\n",
       "   name='models/text-embedding-004',\n",
       "   output_token_limit=1,\n",
       "   supported_actions=[\n",
       "     'embedContent',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='004'\n",
       " ),\n",
       " Model(\n",
       "   description='Obtain a distributed representation of a text.',\n",
       "   display_name='Gemini Embedding Experimental 03-07',\n",
       "   input_token_limit=8192,\n",
       "   name='models/gemini-embedding-exp-03-07',\n",
       "   output_token_limit=1,\n",
       "   supported_actions=[\n",
       "     'embedContent',\n",
       "     'countTextTokens',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='exp-03-07'\n",
       " ),\n",
       " Model(\n",
       "   description='Obtain a distributed representation of a text.',\n",
       "   display_name='Gemini Embedding Experimental',\n",
       "   input_token_limit=8192,\n",
       "   name='models/gemini-embedding-exp',\n",
       "   output_token_limit=1,\n",
       "   supported_actions=[\n",
       "     'embedContent',\n",
       "     'countTextTokens',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='exp-03-07'\n",
       " ),\n",
       " Model(\n",
       "   description='Obtain a distributed representation of a text.',\n",
       "   display_name='Gemini Embedding 001',\n",
       "   input_token_limit=2048,\n",
       "   name='models/gemini-embedding-001',\n",
       "   output_token_limit=1,\n",
       "   supported_actions=[\n",
       "     'embedContent',\n",
       "     'countTextTokens',\n",
       "     'countTokens',\n",
       "     'asyncBatchEmbedContent',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.',\n",
       "   display_name='Model that performs Attributed Question Answering.',\n",
       "   input_token_limit=7168,\n",
       "   name='models/aqa',\n",
       "   output_token_limit=1024,\n",
       "   supported_actions=[\n",
       "     'generateAnswer',\n",
       "   ],\n",
       "   temperature=0.2,\n",
       "   top_k=40,\n",
       "   top_p=1.0,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Vertex served Imagen 4.0 model',\n",
       "   display_name='Imagen 4 (Preview)',\n",
       "   input_token_limit=480,\n",
       "   name='models/imagen-4.0-generate-preview-06-06',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predict',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='01'\n",
       " ),\n",
       " Model(\n",
       "   description='Vertex served Imagen 4.0 ultra model',\n",
       "   display_name='Imagen 4 Ultra (Preview)',\n",
       "   input_token_limit=480,\n",
       "   name='models/imagen-4.0-ultra-generate-preview-06-06',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predict',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='01'\n",
       " ),\n",
       " Model(\n",
       "   description='Vertex served Imagen 4.0 model',\n",
       "   display_name='Imagen 4',\n",
       "   input_token_limit=480,\n",
       "   name='models/imagen-4.0-generate-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predict',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Vertex served Imagen 4.0 ultra model',\n",
       "   display_name='Imagen 4 Ultra',\n",
       "   input_token_limit=480,\n",
       "   name='models/imagen-4.0-ultra-generate-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predict',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Vertex served Imagen 4.0 Fast model',\n",
       "   display_name='Imagen 4 Fast',\n",
       "   input_token_limit=480,\n",
       "   name='models/imagen-4.0-fast-generate-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predict',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.',\n",
       "   display_name='Veo 2',\n",
       "   input_token_limit=480,\n",
       "   name='models/veo-2.0-generate-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predictLongRunning',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='2.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Veo 3',\n",
       "   display_name='Veo 3',\n",
       "   input_token_limit=480,\n",
       "   name='models/veo-3.0-generate-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predictLongRunning',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='3.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Veo 3 fast',\n",
       "   display_name='Veo 3 fast',\n",
       "   input_token_limit=480,\n",
       "   name='models/veo-3.0-fast-generate-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predictLongRunning',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='3.0'\n",
       " ),\n",
       " Model(\n",
       "   description='Veo 3.1',\n",
       "   display_name='Veo 3.1',\n",
       "   input_token_limit=480,\n",
       "   name='models/veo-3.1-generate-preview',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predictLongRunning',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='3.1'\n",
       " )]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd5cce6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/embedding-gecko-001',\n",
       " 'models/gemini-2.5-flash',\n",
       " 'models/gemini-2.5-pro',\n",
       " 'models/gemini-2.0-flash-exp',\n",
       " 'models/gemini-2.0-flash',\n",
       " 'models/gemini-2.0-flash-001',\n",
       " 'models/gemini-2.0-flash-exp-image-generation',\n",
       " 'models/gemini-2.0-flash-lite-001',\n",
       " 'models/gemini-2.0-flash-lite',\n",
       " 'models/gemini-2.0-flash-lite-preview-02-05',\n",
       " 'models/gemini-2.0-flash-lite-preview',\n",
       " 'models/gemini-2.0-pro-exp',\n",
       " 'models/gemini-2.0-pro-exp-02-05',\n",
       " 'models/gemini-exp-1206',\n",
       " 'models/gemini-2.5-flash-preview-tts',\n",
       " 'models/gemini-2.5-pro-preview-tts',\n",
       " 'models/gemma-3-1b-it',\n",
       " 'models/gemma-3-4b-it',\n",
       " 'models/gemma-3-12b-it',\n",
       " 'models/gemma-3-27b-it',\n",
       " 'models/gemma-3n-e4b-it',\n",
       " 'models/gemma-3n-e2b-it',\n",
       " 'models/gemini-flash-latest',\n",
       " 'models/gemini-flash-lite-latest',\n",
       " 'models/gemini-pro-latest',\n",
       " 'models/gemini-2.5-flash-lite',\n",
       " 'models/gemini-2.5-flash-image-preview',\n",
       " 'models/gemini-2.5-flash-image',\n",
       " 'models/gemini-2.5-flash-preview-09-2025',\n",
       " 'models/gemini-2.5-flash-lite-preview-09-2025',\n",
       " 'models/gemini-3-pro-preview',\n",
       " 'models/gemini-3-pro-image-preview',\n",
       " 'models/nano-banana-pro-preview',\n",
       " 'models/gemini-robotics-er-1.5-preview',\n",
       " 'models/gemini-2.5-computer-use-preview-10-2025',\n",
       " 'models/embedding-001',\n",
       " 'models/text-embedding-004',\n",
       " 'models/gemini-embedding-exp-03-07',\n",
       " 'models/gemini-embedding-exp',\n",
       " 'models/gemini-embedding-001',\n",
       " 'models/aqa',\n",
       " 'models/imagen-4.0-generate-preview-06-06',\n",
       " 'models/imagen-4.0-ultra-generate-preview-06-06',\n",
       " 'models/imagen-4.0-generate-001',\n",
       " 'models/imagen-4.0-ultra-generate-001',\n",
       " 'models/imagen-4.0-fast-generate-001',\n",
       " 'models/veo-2.0-generate-001',\n",
       " 'models/veo-3.0-generate-001',\n",
       " 'models/veo-3.0-fast-generate-001',\n",
       " 'models/veo-3.1-generate-preview']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91da2bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(\n",
       "   description='Veo 3.1 fast',\n",
       "   display_name='Veo 3.1 fast',\n",
       "   input_token_limit=480,\n",
       "   name='models/veo-3.1-fast-generate-preview',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'predictLongRunning',\n",
       "   ],\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='3.1'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.0 Flash 001',\n",
       "   display_name='Gemini 2.0 Flash 001',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.0-flash-live-001',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'bidiGenerateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini Live 2.5 Flash Preview',\n",
       "   display_name='Gemini Live 2.5 Flash Preview',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-live-2.5-flash-preview',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'bidiGenerateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Flash Live Preview',\n",
       "   display_name='Gemini 2.5 Flash Live Preview',\n",
       "   input_token_limit=1048576,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-live-preview',\n",
       "   output_token_limit=65536,\n",
       "   supported_actions=[\n",
       "     'bidiGenerateContent',\n",
       "     'countTokens',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='001'\n",
       " ),\n",
       " Model(\n",
       "   description='Latest release of Gemini 2.5 Flash Native Audio',\n",
       "   display_name='Gemini 2.5 Flash Native Audio Latest',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-native-audio-latest',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'countTokens',\n",
       "     'bidiGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='Gemini 2.5 Flash Native Audio Latest'\n",
       " ),\n",
       " Model(\n",
       "   description='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
       "   display_name='Gemini 2.5 Flash Native Audio Preview 09-2025',\n",
       "   input_token_limit=131072,\n",
       "   max_temperature=2.0,\n",
       "   name='models/gemini-2.5-flash-native-audio-preview-09-2025',\n",
       "   output_token_limit=8192,\n",
       "   supported_actions=[\n",
       "     'countTokens',\n",
       "     'bidiGenerateContent',\n",
       "   ],\n",
       "   temperature=1.0,\n",
       "   thinking=True,\n",
       "   top_k=64,\n",
       "   top_p=0.95,\n",
       "   tuned_model_info=TunedModelInfo(),\n",
       "   version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19'\n",
       " )]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "180be600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "for m in model_list:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26bedbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import perplexity\n",
    "from perplexity import Perplexity\n",
    "\n",
    "client = Perplexity(api_key=get_key(\".env\", \"PERPLEXITY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xai_sdk\n",
    "\n",
    "client = xai_sdk.Client(api_key=get_key(\".env\", \"XAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be148fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mistralai\n",
    "from mistralai import Mistral\n",
    "\n",
    "client = Mistral(api_key=get_key(\".env\", \"MISTRAL_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, InferenceClient\n",
    "\n",
    "client = HfApi(token=get_key(\".env\", \"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4002ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comfy_sdk import ComfyUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091f8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=ComfyUI(port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0705705d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ilxl/Illustrious-XL-v1.0.safetensors',\n",
       " 'sd15/AOM3A1B_orangemixs.safetensors',\n",
       " 'sd15/Anything-ink.safetensors',\n",
       " 'sd15/AnythingXL_v50.safetensors',\n",
       " 'sd15/Counterfeit-V3.0_fix_fp16.safetensors',\n",
       " 'sd15/anythingV3_fp16.safetensors',\n",
       " 'sd15/sd-v1-5-inpainting.ckpt',\n",
       " 'sd15/v1-5-pruned-emaonly.safetensors',\n",
       " 'sd35_large/emi3.safetensors',\n",
       " 'sdxl/AnythingXL_xl.safetensors',\n",
       " 'sdxl/AnythingXL_xlHyper8stepsCFG1.safetensors',\n",
       " 'sdxl/animagine-xl-3.1.safetensors',\n",
       " 'sdxl/animagine-xl-4.0-opt.safetensors',\n",
       " 'sdxl/fp8/animagine-xl-4.0-opt-fp8.safetensors',\n",
       " 'sdxl/sd_xl_base_1.0.safetensors',\n",
       " 'sdxl/sd_xl_refiner_1.0.safetensors']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list('checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0c5907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ilxl/Hologram headless illusXL v3.safetensors',\n",
       " 'ilxl/Succubus_Mary_Lapis_V1.safetensors',\n",
       " 'ilxl/akane_sakuramori-kurakon_s1-ixl-anime-soralz.safetensors',\n",
       " 'ilxl/checkpoint-e40_s960.safetensors',\n",
       " 'ilxl/fp8/checkpoint-e40_s960-fp8.safetensors',\n",
       " 'ilxl/sugekaeman_IL.safetensors',\n",
       " 'ilxl/sugekaewoman_IL.safetensors',\n",
       " 'pony/Headless control collar ponyXL v1.safetensors',\n",
       " 'pony/Tomboy_Style_Pony.safetensors',\n",
       " 'pony/akane_sakuramori-kurakon_s1-anime-soralz.safetensors',\n",
       " 'pony/saito_houjou-kurakon_s1-anime-soralz.safetensors',\n",
       " 'pony/sdxlpony_disembodiedhead-t1-000006.safetensors',\n",
       " 'pony/sdxlponyheadless-000006.safetensors',\n",
       " 'pony/sugekaeman_vp.safetensors',\n",
       " 'pony/sugekaewoman_vp.safetensors',\n",
       " 'qwen_image/Qwen-Image-Lightning-4steps-V2.0-bf16.safetensors',\n",
       " 'sd15/Anime Enhancer - Midrange - ClipSkip1 - [Concept] - Version 1.safetensors',\n",
       " 'sd15/DisembodiedHeadV2.safetensors',\n",
       " 'sd15/HeadinJar.safetensors',\n",
       " 'sd15/Headless-Holding head- T13.safetensors',\n",
       " 'sd15/Tomboy.safetensors',\n",
       " 'sd15/TomboyBuzzcut1-2-0805.safetensors',\n",
       " 'sd15/concept-shortbangs.safetensors',\n",
       " 'sd15/eugeo-10.safetensors',\n",
       " 'sd15/kirito-10.safetensors',\n",
       " 'sd15/lcm-lora-sdv1-5.safetensors',\n",
       " 'sd15/princess_carry_v0.1.safetensors',\n",
       " 'sd15/shima920_v2-000011.safetensors',\n",
       " 'sd15/tcd-lora-sdv1-5.safetensors',\n",
       " 'sd35_large/Tomboy_for_SD3.safetensors',\n",
       " 'sd35_large/tomboy-style-lora-for-sd35-large.safetensors',\n",
       " 'sdxl/A_SHort_Cut_v3_SDXL.safetensors',\n",
       " 'sdxl/Better hands - SDXL v2.0.safetensors',\n",
       " 'sdxl/EnvyTomboyXL01.safetensors',\n",
       " 'sdxl/SAO Kirito SDXL Satu.safetensors',\n",
       " 'sdxl/SDXL_Dark_Knight.safetensors',\n",
       " 'sdxl/SDXL_disembodied head_headless.safetensors',\n",
       " 'sdxl/XL-Eugeo-SAO-AnimagineXL3.1-v1.safetensors',\n",
       " 'sdxl/[Yue]Paintingboys-SDXL.safetensors',\n",
       " 'sdxl/abec_XL.safetensors',\n",
       " 'sdxl/add_details_xl.safetensors',\n",
       " 'sdxl/aino-koito-xl-animagine-xl-4-v1.safetensors',\n",
       " 'sdxl/checkpoint-e36_s756.safetensors',\n",
       " 'sdxl/checkpoint-e40_s640.safetensors',\n",
       " 'sdxl/chibi_anime.safetensors',\n",
       " 'sdxl/enhancerV4-xl.safetensors',\n",
       " 'sdxl/fp8/aino-koito-xl-animagine-xl-4-v1-fp8.safetensors',\n",
       " 'sdxl/fp8/checkpoint-e36_s756-fp8.safetensors',\n",
       " 'sdxl/fp8/chibi_anime-fp8.safetensors',\n",
       " 'sdxl/fp8/headswap-xl-animagine-fp8.safetensors',\n",
       " 'sdxl/fp8/makotono-aoi-xl-animagine-xl-4-v1-fp8.safetensors',\n",
       " 'sdxl/fp8/minami-asuka-xl-animagine-xl-4-v1-fp8.safetensors',\n",
       " 'sdxl/fp8/tomboy-xl-animagine-fp8.safetensors',\n",
       " 'sdxl/headswap-xl-animagine.safetensors',\n",
       " 'sdxl/lcm-lora-sdxl.safetensors',\n",
       " 'sdxl/makotono-aoi-xl-animagine-xl-4-v1.safetensors',\n",
       " 'sdxl/minami-asuka-xl-animagine-xl-4-v1.safetensors',\n",
       " 'sdxl/out4.safetensors',\n",
       " 'sdxl/sugekaeman_v3.1.safetensors',\n",
       " 'sdxl/sugekaewoman_v3.1.safetensors',\n",
       " 'sdxl/tcd-lora-sdxl.safetensors',\n",
       " 'sdxl/tomboy-xl-animagine.safetensors',\n",
       " 'wan22/livewallpaper_wan22_5b_TI2V_000005000.safetensors']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.list('loras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd42a76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepl\n",
    "\n",
    "deepl_client = deepl.DeepLClient(auth_key=get_key('.env', 'DEEPL_AUTH_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5e0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = deepl_client.translate_text(\"     . ?\", target_lang=\"EN-US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677d8750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'All conversations in all sessions will be deleted. Do you want to continue?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b8c0f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qwen3-8b',\n",
       " 'llama-4-scout-17b-16e-instruct',\n",
       " 'google_gemma-3-27b-it-qat',\n",
       " 'google/gemma-3-12b',\n",
       " 'trillion-7b-preview',\n",
       " 'meta-llama-3.2-11b-vision-instruct-mlx@4bit',\n",
       " 'meta-llama-3.2-11b-vision-instruct-mlx@6bit',\n",
       " 'meta-llama-3.1-8b-instruct',\n",
       " 'mistral-small-3.2-24b-instruct-2506-mlx-gs128',\n",
       " 'mistral-small-3.2-24b-instruct-2506',\n",
       " 'qwen_qwen3-vl-30b-a3b-thinking',\n",
       " 'qwen_qwen3-vl-30b-a3b-instruct',\n",
       " 'openai/gpt-oss-20b-mxfp4-q8',\n",
       " 'qwen/qwen3-vl-8b',\n",
       " 'qwen3-vl-8b-thinking-mlx',\n",
       " 'qwen3-30b-a3b-instruct-2507',\n",
       " 'openai/gpt-oss-20b',\n",
       " 'qwen3-14b-mlx',\n",
       " 'mistral-small-24b-instruct-2501',\n",
       " 'qwen3-8b-mlx']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lmstudio as lms\n",
    "\n",
    "client = lms.Client(api_host=\"localhost:1234\")\n",
    "downloaded_llm = client.list_downloaded_models(\"llm\")\n",
    "\n",
    "llm = []\n",
    "\n",
    "for m in downloaded_llm:\n",
    "    llm.append(m.model_key)\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a862b981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qwen3-vl:8b', 'gpt-oss:20b']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "llm = []\n",
    "\n",
    "client = ollama.Client(host=\"http://localhost:11434\")\n",
    "models = client.list().models\n",
    "\n",
    "for m in models:\n",
    "    llm.append(m.model)\n",
    "\n",
    "llm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
